{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "U4-S3-DNN (Python 3.7)",
      "language": "python",
      "name": "u4-s3-dnn"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "LS_DS_431_RNN_and_LSTM_Assignment.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tclack88/DS-Unit-4-Sprint-3-Deep-Learning/blob/master/module1-rnn-and-lstm/LS_DS_431_RNN_and_LSTM_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zA3OlIe9m5iq",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
        "\n",
        "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
        "\n",
        "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
        "\n",
        "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
        "\n",
        "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
        "\n",
        "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
        "\n",
        "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
        "\n",
        "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4BTIog51TsG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVq9TmAVqO_D",
        "colab_type": "text"
      },
      "source": [
        "### import and clean text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHE9m1iInGb2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "fcda38dd-f58a-4932-c7a0-a1d668e8cade"
      },
      "source": [
        "!wget https://www.gutenberg.org/files/100/100-0.txt && ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-16 22:41:41--  https://www.gutenberg.org/files/100/100-0.txt\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5777367 (5.5M) [text/plain]\n",
            "Saving to: ‘100-0.txt’\n",
            "\n",
            "100-0.txt           100%[===================>]   5.51M  4.20MB/s    in 1.3s    \n",
            "\n",
            "2019-12-16 22:41:43 (4.20 MB/s) - ‘100-0.txt’ saved [5777367/5777367]\n",
            "\n",
            "100-0.txt  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRmKy6d_qRl0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvVky-VHnTOS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = '100-0.txt'\n",
        "text = ''\n",
        "with open(data, 'r') as f:\n",
        "  text += f.read()\n",
        "\n",
        "text = re.sub(r'[^A-Za-z 0-9]', '',text.replace('\\n', ' ').replace('\\t', ' ')) # replace newlines and tabs with spaces\n",
        "text = ' '.join(text.split()) # remove excess spaces between characters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUU3VbP4ojF2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "50d415cc-f5a3-4973-da48-a0abaad52279"
      },
      "source": [
        "text[:200]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Project Gutenbergs The Complete Works of William Shakespeare by William Shakespeare This eBook is for the use of anyone anywhere in the United States and most other parts of the world at no cost and w'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BeKF8Fus1xg",
        "colab_type": "text"
      },
      "source": [
        "### Create relevant variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCLLKnNatBDD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chars = list(set(list(text)))\n",
        "\n",
        "int_char = {i:c for i,c in enumerate(chars)}\n",
        "char_int = {c:i for i,c in enumerate(chars)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddd9gqz0sop1",
        "colab_type": "text"
      },
      "source": [
        "### Create sequence data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goghuFk4vpL-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len = 60\n",
        "step = 5\n",
        "\n",
        "encoded = [char_int[c] for c in text]\n",
        "\n",
        "sequences = []\n",
        "next_chars = []\n",
        "\n",
        "for i in range(0, len(encoded) - max_len, step):\n",
        "  sequences.append(encoded[i : i + max_len])\n",
        "  next_chars.append(encoded[i + max_len])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ltj1je1fp5rO",
        "colab_type": "text"
      },
      "source": [
        "### create matrix inputs and predicted values (X and y)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuKctYbtytf8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.zeros((len(sequences), max_len, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sequences), len(chars)), dtype=np.bool)\n",
        "\n",
        "for i, sequence in enumerate(sequences):\n",
        "  for s, char in enumerate(sequence):\n",
        "    X[i, s, char] = 1\n",
        "  y[i, next_chars[i]] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2O9JTUcK4hDt",
        "colab_type": "text"
      },
      "source": [
        "## Create LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_g566AN4lbN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.callbacks import LambdaCallback"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4jfIUMy41Cr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(max_len, len(chars))))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=.01))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDqZg5CW9tWO",
        "colab_type": "text"
      },
      "source": [
        "### running definitions taken from lecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EH38DLLtDXND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-I-SIOCr6Vb0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyvIAHY09xXD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def on_epoch_end(epoch, _):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "\n",
        "    start_index = random.randint(0, len(text) - max_len - 1)\n",
        "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
        "        print('----- diversity:', diversity)\n",
        "\n",
        "        generated = ''\n",
        "        sentence = text[start_index: start_index + max_len]\n",
        "        generated += sentence\n",
        "        print('----- Generating with seed: \"' + sentence + '\"')\n",
        "        sys.stdout.write(generated)\n",
        "\n",
        "        for i in range(400):\n",
        "            x_pred = np.zeros((1, max_len, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_int[char]] = 1.\n",
        "\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_char = int_char[next_index]\n",
        "\n",
        "            sentence = sentence[1:] + next_char\n",
        "\n",
        "            sys.stdout.write(next_char)\n",
        "            sys.stdout.flush()\n",
        "        print()\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZRMvnrV91Ws",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3b4324b7-e3ef-4d04-83d2-9c823d85a480"
      },
      "source": [
        "model.fit(X, y, batch_size=512, epochs=5, callbacks=[print_callback])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1001479 samples\n",
            "Epoch 1/5\n",
            "1001472/1001479 [============================>.] - ETA: 0s - loss: 2.0563\n",
            "----- Generating text after Epoch: 0\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"If the cook help to make the gluttony you help to make the d\"\n",
            "If the cook help to make the gluttony you help to make the death the mean the state and so so shall be the send the common the street the common the country the see the street the more the stream the sea and the son the set the street to the see the seem and so she shall be so me to the send the such a good constant the see the consent the death the send the fair there is so see the s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "eem and the street and the say the fair present the sender to the country\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"If the cook help to make the gluttony you help to make the d\"\n",
            "If the cook help to make the gluttony you help to make the deep lay me the constart to death me with the love a the such for he he will comes I must thou art the stand the streams on the sun and seem where be not the sense but were a death in the liver be the body I shall be sir and like thee traiting were the seemd and a house the scance like her heart he so the death of my fier be come to the with the more to he doth he is the proclaim And so will the si\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"If the cook help to make the gluttony you help to make the d\"\n",
            "If the cook help to make the gluttony you help to make the death MACBETH What nurse boy bele ye follows to if vick certain to me complates procasos Where be but curcing the drunking I shall not be and holding this weasin wings those sequeed another favour Let for out or he virtue and speak she will be at thee Then let to you abitam claid hero me I speeches And theres such lord  and month sidua us My livil FRONCE He lar fled Canrythor King for you wood to t\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"If the cook help to make the gluttony you help to make the d\"\n",
            "If the cook help to make the gluttony you help to make the da ANTONIO We prefises Leap thee Than my holided scox downs the Priam laagerny PRINCE Poof this construct The under our worsham Be Scen III CLAUDIO NERIUS Now state The dearly prefluskess the fixd froncie breveray knre must tide of his spicresty in worn so PIOVIN Toten life MARIN Jes if with but forth given To he were hot dessing alack that De distoicianclos their place of comfient the in Nay confe\n",
            "1001479/1001479 [==============================] - 1270s 1ms/sample - loss: 2.0562\n",
            "Epoch 2/5\n",
            "1001472/1001479 [============================>.] - ETA: 0s - loss: 2.0552\n",
            "----- Generating text after Epoch: 1\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"seek me out His counsel now might do me golden service For t\"\n",
            "seek me out His counsel now might do me golden service For the see the most I shall pardon the son and the siges the seen the revenge the send the state the dead the sta the stive the stra she shall be the such a soul and the father The I will not speak and the state I have see the foon to the sea the state here I will be me the shalld the seem the strength the strength the stream of a such a shall she hath no man look of the sea the shalld here and the st\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"seek me out His counsel now might do me golden service For t\"\n",
            "seek me out His counsel now might do me golden service For the father And be shall side the love set the state that they dome are return I offended the therefore your life And see the Duke of the Kins base so your fathers such a husband And the fine a for the such a liege in his father to the dead do a so see your ear of your send to the Ill you shall be then that love the very ha devil for my father the old such a word with bloody a part all the suffly my\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"seek me out His counsel now might do me golden service For t\"\n",
            "seek me out His counsel now might do me golden service For the I hide he do be impeals Within A pittaget I am a thanks to come yiels the pallaldd no thought Out with desurvopan WOLCESTER Faith eat O look Do our beep up Messeny handmarhVeres This so but when This all thisling shall fear mid with one wight Ay PORT A this compare you to mes with the do Ill here ill he she shall not pannes can I sweet Thbable and pamen stoul VOLAS Sir never thus ho then with S\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"seek me out His counsel now might do me golden service For t\"\n",
            "seek me out His counsel now might do me golden service For thou wilcfest delthers I FAFF Thou LArvAlarugst it It hath dankinly hast thy that we priive hence ESCALUS Might you says Exit forblead She receared hh gos that if we sh NORBF tidss that prile a ligat No cyrfecks Tis child weak Ed this smparainests resamor wibrus ovetbhstilos em Vaulslard suchink and yonds thousasinclps in bern look And our heart andrst hings indeeds our lausys he swift word upon ev\n",
            "1001479/1001479 [==============================] - 1266s 1ms/sample - loss: 2.0552\n",
            "Epoch 3/5\n",
            "1001472/1001479 [============================>.] - ETA: 0s - loss: 1.5747\n",
            "----- Generating text after Epoch: 2\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \" form DROMIO OF SYRACUSE No I am an ape LUCIANA If thou art \"\n",
            " form DROMIO OF SYRACUSE No I am an ape LUCIANA If thou art a word the leade the mons the state the least they die with the streasure the stars the proceed the word the word the bare the wit the discomming the stars the more the father with the word the comment the present the death the part the sight the word with the strent the strence the profess with my heart the word with the sight the lie the stand the command the state and the word the strumpet of t\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \" form DROMIO OF SYRACUSE No I am an ape LUCIANA If thou art \"\n",
            " form DROMIO OF SYRACUSE No I am an ape LUCIANA If thou art his grave And made the the party with the rean the lieutents thede she can we can go the drink the witch the strange of the true of the water the door way tis thete the battle the word her with the honesty grant of a rest company the proceed the lady willing best But they die in the strange Exit and the charge by my so lie The praise the commander that with the world Sitter I the done And right me\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \" form DROMIO OF SYRACUSE No I am an ape LUCIANA If thou art \"\n",
            " form DROMIO OF SYRACUSE No I am an ape LUCIANA If thou art thou peacetion And I diest challenge seem Youne and the word the le assury passd is Go to this troninaness Leave us go or you purse again You cabs my exembling cried To her youth And They were the vapur hauph to his least that never does ided Being you withal die How shame Overtrain your most answer age yet estor sheph niecees knunded you world of bear your love to retrent but if Iach they late ag\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \" form DROMIO OF SYRACUSE No I am an ape LUCIANA If thou art \"\n",
            " form DROMIO OF SYRACUSE No I am an ape LUCIANA If thou art torture Ill dayner Warninb withers but you fimbrale hanged he in Ill we thank I have yaur good COBRISTON Leamstey is confeashsemble hourd unyot lover my labiterwomy fray roops thy  Bu it is the wind Wishin SHALDO My possiss it chant Good he willly Johe Penteeres Adyliqu him daughter Lec Deffen coursery CATEAN Hark not poor many MisTragecly stertHERRLIUS Ashitual ULYS Break from your Thanele yourth\n",
            "1001479/1001479 [==============================] - 1266s 1ms/sample - loss: 1.5747\n",
            "Epoch 4/5\n",
            "1001472/1001479 [============================>.] - ETA: 0s - loss: 1.5830\n",
            "----- Generating text after Epoch: 3\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"ightie winters this I told them who A Lasse of foureteene br\"\n",
            "ightie winters this I told them who A Lasse of foureteene brother that I am a should the sight and the father and the sir and the sir the companion the sir the word the part the provide and the sight the for the companion and the present the privation that the part the company that the shall the sir the world and a sir the company and a should the father and the sight of the pride the world the than and the prince and the stage the son the life whose honou\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"ightie winters this I told them who A Lasse of foureteene br\"\n",
            "ightie winters this I told them who A Lasse of foureteene brave brothers That so and a appears to let the world broken O the polon her The companion of his lord you let us show the man BARDOLPH Shall he are of the Come and therefore Bid the late and for the child the king to the hand that so and under a thing the fine and come Thou are the love thou art thou and for have me That the brothers sir Her father who thoughts the power of car Thou wouldst stand t\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"ightie winters this I told them who A Lasse of foureteene br\"\n",
            "ightie winters this I told them who A Lasse of foureteene brooks than what come hear Sir DROMIO Dishe Enter Ton follow despite at first should they would speak nay by me you like do the leave her pressions of fort You like of the modest and FISTRIA KING Theres and please thou are the old Till attendants This grave and thou ries worthy to go ADRIO Of hold lumberen by ball so la speak and with a heaven than where is yonder you SSURRICR Bw Alaray priof she Pi\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"ightie winters this I told them who A Lasse of foureteene br\"\n",
            "ightie winters this I told them who A Lasse of foureteene brought drops born Achild LUCIUS Some brew I find who dwived as as BECTHARD I shall come your Darry and thou wilt ton this Hes prisot him they my forlikn flaction come nightst Julianation Suppels a cast As ther The craim DUKE I life GEATL Let OTHELLO Lies L Tber of grought thrance Gudls begally dle MRS PROSPER Prince to sent a nexts confor That than Attendous shoul DEERRLIAN Anener Some doth with yo\n",
            "1001479/1001479 [==============================] - 1264s 1ms/sample - loss: 1.5830\n",
            "Epoch 5/5\n",
            "1001472/1001479 [============================>.] - ETA: 0s - loss: 3.4866\n",
            "----- Generating text after Epoch: 4\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"them and would send them back the plague Could I but catch i\"\n",
            "them and would send them back the plague Could I but catch in the the lord of the was the more the see the see the see the save the the and th sorrow the stre the save the stre the save the stresh you the stresh the the the that and with the save the sir the sea her the want the save the the see the see the save the were and the LADIER What a see the worthen and the whiche and the warch the hear and the presene with the stre a stres and shallESSCENE What s\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"them and would send them back the plague Could I but catch i\"\n",
            "them and would send them back the plague Could I but catch it and wherear of he the safer have and the wit but be in thi scherwank the sorrow the mans he no suppolace maken let up the save the some and now a very I am for my hears for the sore her coulth you for me of the meSToe the spease And the withe theks let you this and to her withe his consume you heprompd my from thus of an I labour s reture The grood and let me must she masture our hour the garren\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"them and would send them back the plague Could I but catch i\"\n",
            "them and would send them back the plague Could I but catch inmore of the he thereverishduf book Away he Her Noll so are to Regnive nogly pitst  wI quel I do no and wOLDuARAS QUEEN Mastere whichpakerann Romproson but wouGd in he Troubl oun thatsworteor worm When pladds than PAGO evenceer forlood CYessbRr wricentwichous scurnt and maTtembre more a are of merwAMROM eyewiae gent beveully give to love the less FORD Nor meCruble are from or reverithisgides jone \n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"them and would send them back the plague Could I but catch i\"\n",
            "them and would send them back the plague Could I but catch in hocspants Feare on this snoltraghovtergen dack ons andkspse Ar ut maPneck that frele be shund My DUKE You is b vitery Ill garm knop are  s day dost Fire Brutur m chim THAR Caits wholk in maty I aim Lows your teury Hivd are I hence clks KING man Severer of mert give other Jerepuse withe Dawsmed Jeverall of dauguof MARGAROMAN You it welm sogdonieds shold on croy whathe Ay Know be fours I the poort\n",
            "1001479/1001479 [==============================] - 1270s 1ms/sample - loss: 3.4866\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd511420908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zE4a4O7Bp5x1"
      },
      "source": [
        "# Resources and Stretch Goals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uT3UV3gap9H6"
      },
      "source": [
        "## Stretch goals:\n",
        "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
        "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
        "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
        "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
        "- Run on bigger, better data\n",
        "\n",
        "## Resources:\n",
        "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
        "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
        "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
        "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
        "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
      ]
    }
  ]
}