{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_431_Intro_to_NN_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tclack88/DS-Unit-4-Sprint-2-Neural-Networks/blob/master/module1-Intro-to-Neural-Networks/LS_DS_421_Intro_to_NN_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dVfaLrjLvxvQ"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "# Neural Networks\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2 Assignment 1*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wxtoY12mwmih"
      },
      "source": [
        "## Define the Following:\n",
        "You can add image, diagrams, whatever you need to ensure that you understand the concepts below.\n",
        "\n",
        "### Input Layer:\n",
        "Array input which is analogous to the independent variables of a function\n",
        "### Hidden Layer:\n",
        "If it's neither the input nor the prediction nodes, it's apart of the hidden layer. The hidden layer contains nodes which hold the output of either the input layer or a previous hidden layer (depending on the depth of the neural net)\n",
        "### Output Layer:\n",
        "The final set of nodes in a neural network. It contains the final output of the neural network\n",
        "### Neuron:\n",
        "A node in the neural network which contains just a single value. These values come from the previous neurons if in the hidden later or output layer based on weights and biases. If these neurons are in the input layer, they are just the starting values\n",
        "### Weight:\n",
        "a number, unique between each neuron-to-neuron connection, which determines how much of the input neuron's value will pass on to the next\n",
        "### Activation Function:\n",
        "The output of this is actually what determines the value of each neuron (based on the weights and biases. A good choice is something which takes any values on the input but whose output is restricted to between 0 and 1 such as a sigmoid (from tanh or logistic function) or a simply step function (this is not a hard rule though as with a relu function)\n",
        "### Node Map:\n",
        "A mnemonic used to visualize how the neural network is arranged\n",
        "### Perceptron:\n",
        "A specific and simple neural network consisting of two neurons in the input layer and one neuron in the output layer (no hidden layers exist)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NXuy9WcWzxa4"
      },
      "source": [
        "## Inputs -> Outputs\n",
        "\n",
        "### Explain the flow of information through a neural network from inputs to outputs. Be sure to include: inputs, weights, bias, and activation functions. How does it all flow from beginning to end?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PlSwIJMC0A8F"
      },
      "source": [
        "#### Your Answer Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6sWR43PTwhSk"
      },
      "source": [
        "## Write your own perceptron code that can correctly classify (99.0% accuracy) a NAND gate. \n",
        "\n",
        "| x1 | x2 | y |\n",
        "|----|----|---|\n",
        "| 0  | 0  | 1 |\n",
        "| 1  | 0  | 1 |\n",
        "| 0  | 1  | 1 |\n",
        "| 1  | 1  | 0 |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9b36M-SFkxX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9699ChGS0xJh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "6f180d71-8e1b-4b4c-89e0-7853cd6aa5b3"
      },
      "source": [
        "import pandas as pd\n",
        "data = { 'x1': [0,1,0,1],\n",
        "         'x2': [0,0,1,1],\n",
        "         'y':  [1,1,1,0]\n",
        "       }\n",
        "\n",
        "df = pd.DataFrame.from_dict(data).astype('int')\n",
        "df"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   x1  x2  y\n",
              "0   0   0  1\n",
              "1   1   0  1\n",
              "2   0   1  1\n",
              "3   1   1  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h73-n4IWzs_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(x):\n",
        "  return 1 / (1 - np.exp(-x))\n",
        "    \n",
        "def sigmoid_derivative(x):\n",
        "  sx = sigmoid(x)\n",
        "  return sx * (1 - sx)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Sgh7VFGwnXGH",
        "colab": {}
      },
      "source": [
        "# initialize random weights, assume bias is 0 for simplicity\n",
        "weights = 2*np.random.random((2,1)) - 1\n",
        "# weights = np.zeros((2,1),dtype=float)\n",
        "X = df[['x1','x2']].to_numpy()\n",
        "y = df[['y']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NR4n63JcVHkh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "adfe5263-7d8f-4c4a-86f3-2b0f935376d6"
      },
      "source": [
        "\n",
        "for _ in range(1000):\n",
        "  output = np.dot(X, weights)\n",
        "  error = y - output\n",
        "  adjusted = error * sigmoid_derivative(output)\n",
        "  weights += np.dot(X.T, adjusted)\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVLmcBjpXomQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7237826a-6886-43c7-ebf6-26fcd8b03230"
      },
      "source": [
        "weights"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[nan],\n",
              "       [nan]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nM183N2YYfWI",
        "colab_type": "text"
      },
      "source": [
        "### IGNORE BELOW UNTIL THE PERCEPTROPN IN PART II"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnl2svsfKCIv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def sigmoid(x):\n",
        "#   return 1/(1+np.exp(-x))\n",
        "def error(pred, correct):\n",
        "  return np.sum(np.square(correct - pred))\n",
        "\n",
        "def gradient(pred, correct):\n",
        "  \"\"\" based on derivative of:\n",
        "  (c1 - p1)^2 + (c2 - p2)^2 + ... + (cn - pn)^2\n",
        "  \"\"\"\n",
        "  return 2 * (correct - pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgeB5SUhZHGx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "4468bdc8-afdc-4ac8-d1ed-1c21a0e21e4a"
      },
      "source": [
        "df[['x1','x2']].to_numpy()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [1, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQCGMNmG0xJ5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "5d96bd00-7363-46b3-f0a0-ca7ba1c15c96"
      },
      "source": [
        "input = df[['x1','x2']].to_numpy()\n",
        "correct = df.y.to_numpy()\n",
        "\n",
        "weights = 2*np.random.random((2,1)) - 1 # initialize with 2 random values\n",
        "# weights = np.array([[2,0]])\n",
        "# err = 1 \n",
        "# while err > .01:\n",
        "\n",
        "for _ in range(1000):\n",
        "  pred = np.matmul(input,weights.T)\n",
        "  err = error(pred, correct)\n",
        "# np.matmul(input, weights)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        ],\n",
              "       [ 0.03517442],\n",
              "       [-0.02219107],\n",
              "       [ 0.01298334]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Xf7sdqVs0s4x"
      },
      "source": [
        "## Implement your own Perceptron Class and use it to classify a binary dataset: \n",
        "- [The Pima Indians Diabetes dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv) \n",
        "\n",
        "You may need to search for other's implementations in order to get inspiration for your own. There are *lots* of perceptron implementations on the internet with varying levels of sophistication and complexity. Whatever your approach, make sure you understand **every** line of your implementation and what its purpose is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyI6sE6u0xKH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "9dc9e401-ffe7-449a-d543-1972db26d295"
      },
      "source": [
        "diabetes = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv')\n",
        "diabetes.head()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n",
              "0            6      148             72  ...                     0.627   50        1\n",
              "1            1       85             66  ...                     0.351   31        0\n",
              "2            8      183             64  ...                     0.672   32        1\n",
              "3            1       89             66  ...                     0.167   21        0\n",
              "4            0      137             40  ...                     2.288   33        1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykOsDuQH0xKz",
        "colab_type": "text"
      },
      "source": [
        "Although neural networks can handle non-normalized data, scaling or normalizing your data will improve your neural network's learning speed. Try to apply the sklearn `MinMaxScaler` or `Normalizer` to your diabetes dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tx1pg8dN0xK3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
        "\n",
        "feats = list(diabetes)[:-1]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(diabetes[feats])\n",
        "X = np.hstack((X, np.ones((diabetes.shape[0],1))))\n",
        "y = diabetes[['Outcome']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-W0tiX1F1hh2",
        "colab": {}
      },
      "source": [
        "def sigmoid(x):\n",
        "  return 1 / (1 - np.exp(-x))\n",
        "    \n",
        "def sigmoid_derivative(x):\n",
        "  sx = sigmoid(x)\n",
        "  return sx * (1 - sx)\n",
        "\n",
        "##### Update this Class #####\n",
        "\n",
        "class Perceptron(object):\n",
        "    \n",
        "  def __init__(self, niter = 10):\n",
        "    self.niter = niter\n",
        "    \n",
        "  # def __sigmoid(self, x):\n",
        "  #   return 1 / (1 - np.exp(-x))\n",
        "    \n",
        "  # def __sigmoid_derivative(self, x):\n",
        "  #   self.x = x\n",
        "  #   sx = self.__sigmoid(x)\n",
        "  #   return sx * (1 - sx)\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    \"\"\"Fit training data\n",
        "    X : Training vectors, X.shape : [#samples, #features]\n",
        "    y : Target values, y.shape : [#samples]\n",
        "    \"\"\"\n",
        "\n",
        "  # Randomly Initialize Weights\n",
        "    # self.weights = np.zeros((X.shape[1],1))\n",
        "    self.weights = np.random.random((np.shape(X)[1],1))\n",
        "\n",
        "    for i in range(self.niter):\n",
        "      # Activate!\n",
        "      output = sigmoid(np.dot(X,self.weights))\n",
        "      # Cac error\n",
        "      error = y - output\n",
        "      adjusted = error * sigmoid_derivative(output)\n",
        "      # Update the Weights\n",
        "      self.weights += np.dot(X.T, adjusted)\n",
        "      # Weighted sum of inputs / weights\n",
        "\n",
        "  def predict(self, X):\n",
        "    \"\"\"Return class label after unit step\"\"\"\n",
        "    return sigmoid(np.dot(X, self.weights))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRvSGJ9Coj8P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "perceptron = Perceptron(niter=10000)\n",
        "perceptron.fit(X,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NT3AET4VwzOZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = perceptron.predict(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8q1_7mLxscG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "df040604-a2a1-4bc1-ac72-c61c84ceb4ee"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy_score(pred,y)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3489583333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60ngEshcaRAr",
        "colab_type": "text"
      },
      "source": [
        ":["
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6QR4oAW1xdyu"
      },
      "source": [
        "## Stretch Goals:\n",
        "\n",
        "- Research \"backpropagation\" to learn how weights get updated in neural networks (tomorrow's lecture). \n",
        "- Implement a multi-layer perceptron. (for non-linearly separable classes)\n",
        "- Try and implement your own backpropagation algorithm.\n",
        "- What are the pros and cons of the different activation functions? How should you decide between them for the different layers of a neural network?"
      ]
    }
  ]
}